{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mbp2016/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (28, 28, 1)\n",
    "batch_size = 16\n",
    "\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "input_img = keras.Input(shape=img_shape)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder\n",
    "decoder_input = keras.Input(shape=K.int_shape(z)[1:])\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "x = layers.Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
    "x = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
    "decoder = Model(decoder_input, x)\n",
    "encoder = Model(input_img, z)\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "The KL divergence from  y^  to  y  is simply the difference between cross entropy and entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, z_decoded):\n",
    "    x = K.flatten(x)\n",
    "    z_decoded = K.flatten(z_decoded)\n",
    "    xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "    kl_loss = -5e-4 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "    return K.mean(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = Model(input_img, z_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           401440      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          3300        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          3300        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 28, 28, 1)    1285697     lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,786,409\n",
      "Trainable params: 1,786,409\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 360s 6ms/step - loss: 0.1169 - val_loss: 0.0973\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 356s 6ms/step - loss: 0.0915 - val_loss: 0.0878\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0872 - val_loss: 0.0850\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 324s 5ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 320s 5ms/step - loss: 0.0841 - val_loss: 0.0831\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 321s 5ms/step - loss: 0.0832 - val_loss: 0.0833\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 323s 5ms/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.0822 - val_loss: 0.0823\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 326s 5ms/step - loss: 0.0818 - val_loss: 0.0823\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 326s 5ms/step - loss: 0.0814 - val_loss: 0.0823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fa7ec18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train, shuffle=True, epochs=10, batch_size=batch_size, validation_data=(x_test, x_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "six = y_train_cat[y_train == 6][0]\n",
    "six_image = x_train[y_train == 6][0]\n",
    "\n",
    "eight = y_train_cat[y_train == 9][1]\n",
    "eight_image = x_train[y_train == 9][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(six_image[:, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eight_image[:, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "six_latent = encoder.predict(six_image.reshape([1, 28, 28, 1]))\n",
    "six_decoded = decoder.predict(six_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_decoded = six_decoded.reshape([28, 28, 1])\n",
    "plt.imshow(six_decoded[:, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eight_latent = encoder.predict(eight_image.reshape([1, 28, 28, 1]))\n",
    "eight_decoded = decoder.predict(eight_latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_decoded = eight_decoded.reshape([28, 28, 1])\n",
    "plt.imshow(eight_decoded[:, :, 0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_minus_six_latent = 0.1*six_latent + eight_latent\n",
    "\n",
    "eight_minus_six_decoded = decoder.predict(eight_minus_six_latent)\n",
    "eight_minus_six_decoded = eight_minus_six_decoded.reshape([28, 28, 1])\n",
    "plt.imshow(eight_minus_six_decoded[:, :, 0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"320\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.01\n",
      "0.02\n",
      "0.03\n",
      "0.04\n",
      "0.05\n",
      "0.06\n",
      "0.07\n",
      "0.08\n",
      "0.09\n",
      "0.1\n",
      "0.11\n",
      "0.12\n",
      "0.13\n",
      "0.14\n",
      "0.15\n",
      "0.16\n",
      "0.17\n",
      "0.18\n",
      "0.19\n",
      "0.2\n",
      "0.21\n",
      "0.22\n",
      "0.23\n",
      "0.24\n",
      "0.25\n",
      "0.26\n",
      "0.27\n",
      "0.28\n",
      "0.29\n",
      "0.3\n",
      "0.31\n",
      "0.32\n",
      "0.33\n",
      "0.34\n",
      "0.35\n",
      "0.36\n",
      "0.37\n",
      "0.38\n",
      "0.39\n",
      "0.4\n",
      "0.41\n",
      "0.42\n",
      "0.43\n",
      "0.44\n",
      "0.45\n",
      "0.46\n",
      "0.47\n",
      "0.48\n",
      "0.49\n",
      "0.5\n",
      "0.51\n",
      "0.52\n",
      "0.53\n",
      "0.54\n",
      "0.55\n",
      "0.56\n",
      "0.57\n",
      "0.58\n",
      "0.59\n",
      "0.6\n",
      "0.61\n",
      "0.62\n",
      "0.63\n",
      "0.64\n",
      "0.65\n",
      "0.66\n",
      "0.67\n",
      "0.68\n",
      "0.69\n",
      "0.7\n",
      "0.71\n",
      "0.72\n",
      "0.73\n",
      "0.74\n",
      "0.75\n",
      "0.76\n",
      "0.77\n",
      "0.78\n",
      "0.79\n",
      "0.8\n",
      "0.81\n",
      "0.82\n",
      "0.83\n",
      "0.84\n",
      "0.85\n",
      "0.86\n",
      "0.87\n",
      "0.88\n",
      "0.89\n",
      "0.9\n",
      "0.91\n",
      "0.92\n",
      "0.93\n",
      "0.94\n",
      "0.95\n",
      "0.96\n",
      "0.97\n",
      "0.98\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) + np.cos(y)\n",
    "\n",
    "def g(x):\n",
    "    eight_minus_six_latent = (1-x)*six_latent + x*eight_latent\n",
    "    eight_minus_six_decoded = decoder.predict(eight_minus_six_latent)\n",
    "    eight_minus_six_decoded = eight_minus_six_decoded.reshape([28, 28, 1])\n",
    "    return eight_minus_six_decoded[:, :, 0]\n",
    "\n",
    "# x = np.linspace(0, 1, 120)\n",
    "# y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "for i in range(100):\n",
    "#     x += np.pi / 15.\n",
    "#     y += np.pi / 20.\n",
    "    x = i/100\n",
    "    im = plt.imshow(g(x), animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "# ani.save('dynamic_images.mp4')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('animation.gif', writer='imagemagick', fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
